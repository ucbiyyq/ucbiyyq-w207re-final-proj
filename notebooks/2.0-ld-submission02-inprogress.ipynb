{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Draft for San Francisco Crime Classification\n",
    "\n",
    "https://www.kaggle.com/c/sf-crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.features.build_features import DataFrameSelector, SFCCTransformer, print_summary, prep_submissions, prep_data\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv(\"../data/raw/train.csv.zip\", compression=\"zip\")\n",
    "test_pd = pd.read_csv(\"../data/raw/test.csv.zip\", compression=\"zip\")\n",
    "sample_submissions = pd.read_csv(\"../data/raw/sampleSubmission.csv.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some more features using our custom transformer\n",
    "sfcc = SFCCTransformer()\n",
    "pipe = Pipeline([\n",
    "    (\"transformer\", sfcc)\n",
    "])\n",
    "train_pd = pipe.transform(train_pd)\n",
    "test_pd = pipe.transform(test_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_ids = prep_data(train_pd, test_pd, rs = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#>>> X, y = make_classification(n_samples=1000, n_features=4,\n",
    "#...                            n_informative=2, n_redundant=0,\n",
    "#...                            random_state=0, shuffle=False)\n",
    "#>>> clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "#...                              random_state=0)\n",
    "#>>> clf.fit(X, y)\n",
    "#RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#>>> print(clf.feature_importances_)\n",
    "#[0.14205973 0.76664038 0.0282433  0.06305659]\n",
    "#>>> print(clf.predict([[0, 0, 0, 0]]))\n",
    "#[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# pipeline to prep our data and fit classifiers\n",
    "selector = DataFrameSelector([\"X\", \"Y\"])\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"selector\", selector)\n",
    "    ,(\"clf\", clf)\n",
    "])\n",
    "\n",
    "# TODO add more classifier types and attributes, use list of dicts for alt paths\n",
    "# TODO figure out how to add ensembles to this, maybe with soft voting?\n",
    "# TODO SVM, knn, random forest, etc\n",
    "param_grid = {\n",
    "    \"selector__attribute_names\": [\n",
    "        , [\"X\", \"Y\", \"is_latenight\"]\n",
    "#         ,[\"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "#         ,[\"X\", \"Y\", \"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "    ]\n",
    "    ,\"clf__n_estimators\": [10, 50, 100]\n",
    "    ,\n",
    "    \n",
    "}\n",
    "\n",
    "# TODO figure out how to do stratified kfold by category\n",
    "# TODO figure out how to add bagging to this\n",
    "search = GridSearchCV(pipe, param_grid, iid = True, cv = 3, return_train_score = False, scoring ='neg_log_loss')\n",
    "\n",
    "_ = search.fit(train_data, train_labels)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# pipeline to prep our data and fit classifiers\n",
    "selector = DataFrameSelector([\"X\", \"Y\"])\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"selector\", selector)\n",
    "    ,(\"clf\", clf)\n",
    "])\n",
    "\n",
    "# TODO add more classifier types and attributes, use list of dicts for alt paths\n",
    "# TODO figure out how to add ensembles to this, maybe with soft voting?\n",
    "# TODO SVM, knn, random forest, etc\n",
    "param_grid = {\n",
    "    \"selector__attribute_names\": [\n",
    "        [\"X\", \"Y\"]\n",
    "        , [\"X\", \"Y\", \"is_latenight\"]\n",
    "#         ,[\"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "#         ,[\"X\", \"Y\", \"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "    ]\n",
    "    #,\"knn__n_neighbors\": [3, 16, 26]\n",
    "}\n",
    "\n",
    "# TODO figure out how to do stratified kfold by category\n",
    "# TODO figure out how to add bagging to this\n",
    "search = GridSearchCV(pipe, param_grid, iid = True, cv = 3, return_train_score = False)\n",
    "\n",
    "_ = search.fit(train_data, train_labels)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neuralnetwork import MLPClassifier\n",
    "\n",
    "# pipeline to prep our data and fit classifiers\n",
    "selector = DataFrameSelector([\"X\", \"Y\"])\n",
    "clf = MLPClassifier()\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"selector\", selector)\n",
    "    ,(\"clf\", clf)\n",
    "])\n",
    "\n",
    "# TODO add more classifier types and attributes, use list of dicts for alt paths\n",
    "# TODO figure out how to add ensembles to this, maybe with soft voting?\n",
    "# TODO SVM, knn, random forest, etc\n",
    "param_grid = {\n",
    "    \"selector__attribute_names\": [\n",
    "        [\"X\",\"Y\",\"is_weekend\", 'pdd_BAYVIEW', 'pdd_CENTRAL', 'pdd_INGLESIDE',\n",
    "       'pdd_MISSION', 'pdd_NORTHERN', 'pdd_PARK', 'pdd_RICHMOND',\n",
    "       'pdd_SOUTHERN', 'pdd_TARAVAL', 'pdd_TENDERLOIN', \"is_late_night\", \"month_of_year\"\n",
    "#         ,[\"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "#         ,[\"X\", \"Y\", \"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "    ]\n",
    "    #,\"knn__n_neighbors\": [3, 16, 26]\n",
    "}\n",
    "\n",
    "# TODO figure out how to do stratified kfold by category\n",
    "# TODO figure out how to add bagging to this\n",
    "search = GridSearchCV(pipe, param_grid, iid = True, cv = 3, return_train_score = False)\n",
    "\n",
    "_ = search.fit(train_data, train_labels)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 800k records in both train and test data sets. The train data set has the Category, Descript, and Resolution columns, which are missing from the test data set.\n",
    "\n",
    "We will need to use the test data set to generate the submission to Kaggle.\n",
    "\n",
    "TODO add more plots and EDA from scratch EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 142)\n",
      "(884262, 141)\n"
     ]
    }
   ],
   "source": [
    "print(train_pd.shape)\n",
    "print(test_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>pdd_BAYVIEW</th>\n",
       "      <th>pdd_CENTRAL</th>\n",
       "      <th>pdd_INGLESIDE</th>\n",
       "      <th>pdd_MISSION</th>\n",
       "      <th>pdd_NORTHERN</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_month_sin</th>\n",
       "      <th>day_of_month_cos</th>\n",
       "      <th>day_of_year_sin</th>\n",
       "      <th>day_of_year_cos</th>\n",
       "      <th>week_of_year_sin</th>\n",
       "      <th>week_of_year_cos</th>\n",
       "      <th>month_of_year_sin</th>\n",
       "      <th>month_of_year_cos</th>\n",
       "      <th>quarter_of_year_sin</th>\n",
       "      <th>quarter_of_year_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                  Descript      Resolution     X      Y  \\\n",
       "0        WARRANTS            WARRANT ARREST  ARREST, BOOKED  0.59  0.595   \n",
       "1  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  ARREST, BOOKED  0.59  0.595   \n",
       "\n",
       "   pdd_BAYVIEW  pdd_CENTRAL  pdd_INGLESIDE  pdd_MISSION  pdd_NORTHERN  ...  \\\n",
       "0            0            0              0            0             1  ...   \n",
       "1            0            0              0            0             1  ...   \n",
       "\n",
       "   day_of_month_sin  day_of_month_cos  day_of_year_sin  day_of_year_cos  \\\n",
       "0             0.826             0.118            0.884             0.18   \n",
       "1             0.826             0.118            0.884             0.18   \n",
       "\n",
       "   week_of_year_sin  week_of_year_cos  month_of_year_sin  month_of_year_cos  \\\n",
       "0             0.888             0.185              0.933               0.25   \n",
       "1             0.888             0.185              0.933               0.25   \n",
       "\n",
       "   quarter_of_year_sin  quarter_of_year_cos  \n",
       "0                  1.0                  0.5  \n",
       "1                  1.0                  0.5  \n",
       "\n",
       "[2 rows x 142 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       WARRANTS\n",
       "1                 OTHER OFFENSES\n",
       "2                 OTHER OFFENSES\n",
       "3                  LARCENY/THEFT\n",
       "4                  LARCENY/THEFT\n",
       "5                  LARCENY/THEFT\n",
       "6                  VEHICLE THEFT\n",
       "7                  VEHICLE THEFT\n",
       "8                  LARCENY/THEFT\n",
       "9                  LARCENY/THEFT\n",
       "10                 LARCENY/THEFT\n",
       "11                OTHER OFFENSES\n",
       "12                     VANDALISM\n",
       "13                 LARCENY/THEFT\n",
       "14                  NON-CRIMINAL\n",
       "15                  NON-CRIMINAL\n",
       "16                       ROBBERY\n",
       "17                       ASSAULT\n",
       "18                OTHER OFFENSES\n",
       "19                  NON-CRIMINAL\n",
       "20                 LARCENY/THEFT\n",
       "21                       ROBBERY\n",
       "22                      WARRANTS\n",
       "23                  NON-CRIMINAL\n",
       "24                 LARCENY/THEFT\n",
       "25                  NON-CRIMINAL\n",
       "26                 LARCENY/THEFT\n",
       "27                 LARCENY/THEFT\n",
       "28                 LARCENY/THEFT\n",
       "29                OTHER OFFENSES\n",
       "                   ...          \n",
       "878019            OTHER OFFENSES\n",
       "878020            OTHER OFFENSES\n",
       "878021                 VANDALISM\n",
       "878022             VEHICLE THEFT\n",
       "878023             LARCENY/THEFT\n",
       "878024            OTHER OFFENSES\n",
       "878025            OTHER OFFENSES\n",
       "878026                  WARRANTS\n",
       "878027                  WARRANTS\n",
       "878028                   ASSAULT\n",
       "878029            OTHER OFFENSES\n",
       "878030     SEX OFFENSES FORCIBLE\n",
       "878031                   ASSAULT\n",
       "878032            OTHER OFFENSES\n",
       "878033                 VANDALISM\n",
       "878034                  TRESPASS\n",
       "878035                   ASSAULT\n",
       "878036             LARCENY/THEFT\n",
       "878037                 VANDALISM\n",
       "878038                  WARRANTS\n",
       "878039            OTHER OFFENSES\n",
       "878040                   ASSAULT\n",
       "878041            OTHER OFFENSES\n",
       "878042                   ASSAULT\n",
       "878043            OTHER OFFENSES\n",
       "878044                   ROBBERY\n",
       "878045             LARCENY/THEFT\n",
       "878046             LARCENY/THEFT\n",
       "878047                 VANDALISM\n",
       "878048    FORGERY/COUNTERFEITING\n",
       "Name: Category, Length: 878049, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>pdd_BAYVIEW</th>\n",
       "      <th>pdd_CENTRAL</th>\n",
       "      <th>pdd_INGLESIDE</th>\n",
       "      <th>pdd_MISSION</th>\n",
       "      <th>pdd_NORTHERN</th>\n",
       "      <th>pdd_PARK</th>\n",
       "      <th>pdd_RICHMOND</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_month_sin</th>\n",
       "      <th>day_of_month_cos</th>\n",
       "      <th>day_of_year_sin</th>\n",
       "      <th>day_of_year_cos</th>\n",
       "      <th>week_of_year_sin</th>\n",
       "      <th>week_of_year_cos</th>\n",
       "      <th>month_of_year_sin</th>\n",
       "      <th>month_of_year_cos</th>\n",
       "      <th>quarter_of_year_sin</th>\n",
       "      <th>quarter_of_year_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      X      Y  pdd_BAYVIEW  pdd_CENTRAL  pdd_INGLESIDE  pdd_MISSION  \\\n",
       "0   0  0.766  0.241            1            0              0            0   \n",
       "1   1  0.820  0.218            1            0              0            0   \n",
       "2   2  0.589  0.748            0            0              0            0   \n",
       "\n",
       "   pdd_NORTHERN  pdd_PARK  pdd_RICHMOND  ...  day_of_month_sin  \\\n",
       "0             0         0             0  ...             0.985   \n",
       "1             0         0             0  ...             0.985   \n",
       "2             1         0             0  ...             0.985   \n",
       "\n",
       "   day_of_month_cos  day_of_year_sin  day_of_year_cos  week_of_year_sin  \\\n",
       "0             0.373              0.9              0.2             0.925   \n",
       "1             0.373              0.9              0.2             0.925   \n",
       "2             0.373              0.9              0.2             0.925   \n",
       "\n",
       "   week_of_year_cos  month_of_year_sin  month_of_year_cos  \\\n",
       "0             0.232              0.933               0.25   \n",
       "1             0.232              0.933               0.25   \n",
       "2             0.232              0.933               0.25   \n",
       "\n",
       "   quarter_of_year_sin  quarter_of_year_cos  \n",
       "0                  1.0                  0.5  \n",
       "1                  1.0                  0.5  \n",
       "2                  1.0                  0.5  \n",
       "\n",
       "[3 rows x 141 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 142)\n",
      "(878049,)\n"
     ]
    }
   ],
   "source": [
    "# shuffles the train data\n",
    "# note, we don't need a dev set since we are using cross validation\n",
    "train_data = train_pd.sample(frac=1, random_state = 0)\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "# gets the train labels\n",
    "train_labels = train_data[\"Category\"]\n",
    "\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline to prep our data and fit classifiers\n",
    "selector = DataFrameSelector([\"X\", \"Y\"])\n",
    "km = KMeans(n_clusters = 39)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"selector\", selector)\n",
    "    ,(\"km\", km)\n",
    "])\n",
    "\n",
    "# TODO add more classifier types and attributes, use list of dicts for alt paths\n",
    "# TODO figure out how to add ensembles to this, maybe with soft voting?\n",
    "# TODO SVM, knn, random forest, etc\n",
    "param_grid = {\n",
    "    \"selector__attribute_names\": [\n",
    "        [\"X\", \"Y\"]\n",
    "        , [\"X\", \"Y\", \"is_latenight\"]\n",
    "#         ,[\"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "#         ,[\"X\", \"Y\", \"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# TODO figure out how to do stratified kfold by category\n",
    "# TODO figure out how to add bagging to this\n",
    "search = GridSearchCV(pipe, param_grid, iid = True, cv = 3, return_train_score = False)\n",
    "\n",
    "_ = search.fit(train_data, train_labels)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7f717435b9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# makes predictions against our test data using our best classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredsproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredsproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# makes predictions against our test data using our best classifier\n",
    "predsproba = search.best_estimator_.predict_proba(test_pd)\n",
    "print(predsproba[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884262, 40)\n",
      "   Id  ARSON  ASSAULT  BAD CHECKS  BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
      "0   0    0.0     0.12         0.0      0.0      0.00                 0.0   \n",
      "1   1    0.0     0.15         0.0      0.0      0.00                 0.0   \n",
      "2   2    0.0     0.04         0.0      0.0      0.19                 0.0   \n",
      "\n",
      "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS  ...  \\\n",
      "0                          0.0           0.04          0.0  ...   \n",
      "1                          0.0           0.04          0.0  ...   \n",
      "2                          0.0           0.00          0.0  ...   \n",
      "\n",
      "   SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY  SUICIDE  SUSPICIOUS OCC  TREA  \\\n",
      "0                        0.0              0.0      0.0            0.08   0.0   \n",
      "1                        0.0              0.0      0.0            0.08   0.0   \n",
      "2                        0.0              0.0      0.0            0.04   0.0   \n",
      "\n",
      "   TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  WEAPON LAWS  \n",
      "0       0.0       0.12           0.15      0.12          0.0  \n",
      "1       0.0       0.00           0.00      0.00          0.0  \n",
      "2       0.0       0.08           0.27      0.00          0.0  \n",
      "\n",
      "[3 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# converts predicted probabilities into submission panda\n",
    "submissions = prep_submissions(predsproba, train_pd.Category)\n",
    "\n",
    "print(submissions.shape)\n",
    "print(submissions.head(3))\n",
    "\n",
    "# checks submission has the correct number of rows and columns\n",
    "assert(sample_submissions.shape[0] == submissions.shape[0])\n",
    "assert(sample_submissions.shape[1] == submissions.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save submissions to disk\n",
    "submissions.to_csv(\"../data/processed/submission.csv.gz\", index = False, compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendicies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class DataFrameSelector(BaseEstimator, TransformerMixin): \n",
      "    \"\"\"\n",
      "    Simple helper class, meant make it easier to use Pandas \n",
      "    along with sklearn Pipeline. Create and initate with a \n",
      "    list of features, then when the pipeline transform function\n",
      "    is called, will return a Numpy array of the features.\n",
      "    \n",
      "    See Chap 2 transformation pipelines\n",
      "    \n",
      "    Example:\n",
      "        train_pd = pd.read_csv(\"data.csv\")\n",
      "        num_features = [\"X\", \"Y\"]\n",
      "        num_pipeline = Pipeline([\n",
      "            (\"selector\", DataFrameSelector(num_features))\n",
      "        ])\n",
      "        train_prepared = num_pipeline.transform(train_pd)\n",
      "        \n",
      "    \"\"\"\n",
      "    def __init__(self, attribute_names): \n",
      "        self.attribute_names = attribute_names \n",
      "        \n",
      "    def fit(self, X, y = None): \n",
      "        return self \n",
      "    \n",
      "    def transform(self, X): \n",
      "        return X[self.attribute_names].values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(DataFrameSelector)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFCCTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SFCCTransformer(BaseEstimator, TransformerMixin):\n",
      "    \"\"\"\n",
      "    Helper class for our SanFrancisco Crime Classification project.\n",
      "    \n",
      "    Centralizes transformation logic, and make it easier to use\n",
      "    transformations with Pandas, Pipeline, and gscv. Note, meant to transform\n",
      "    Pandas into Pandas.\n",
      "    \n",
      "    Should use in conjunction with DataFrameSelector and one hot encoders.\n",
      "    \n",
      "    See Chap 2 custom transformers\n",
      "    \n",
      "    \"\"\"\n",
      "    def __init__(self, holiday_calendar = USFederalHolidayCalendar(), latitude_outlier = 50):\n",
      "        self.holiday_calendar = holiday_calendar\n",
      "        self.latitude_outlier = latitude_outlier\n",
      "        \n",
      "    def fit(self, X, y = None):\n",
      "        return self # no fitting\n",
      "    \n",
      "    def transform(self, X, y = None):\n",
      "        \n",
      "        def add_delta(dtt, delta):\n",
      "            \"\"\"\n",
      "            helper funciton, given a Series of dates, \n",
      "            returns Series of delta since the mininum date\n",
      "            \n",
      "            see Linda's baseline code\n",
      "            \"\"\"\n",
      "            res = (dtt - dtt.min()) / np.timedelta64(1, delta)\n",
      "            res = np.floor(res).astype(\"int\")\n",
      "            return res\n",
      "        \n",
      "        def calc_is_holiday(dtt):\n",
      "            \"\"\"\n",
      "            Helper function, given Series dates, \n",
      "            returns Series of 1 if date is holiday, 0 otherwise\n",
      "            \n",
      "            https://stackoverflow.com/questions/29688899/pandas-checking-if-a-date-is-a-holiday-and-assigning-boolean-value\n",
      "            \"\"\"\n",
      "            dt = dtt.dt.date\n",
      "            holidays = self.holiday_calendar.holidays(start = dt.min(), end = dt.max()).date\n",
      "            res = dt.isin(holidays).astype(\"int\")\n",
      "            return res\n",
      "        \n",
      "        def calc_is_latenight(dtt):\n",
      "            hrs = dtt.dt.hour\n",
      "            res = np.ones(shape = hrs.shape)\n",
      "            res[(hrs > 7) & (hrs < 20)] = 0\n",
      "            res = res.astype(\"int\")\n",
      "            return res\n",
      "        \n",
      "        # creates a copy of the input dataframe\n",
      "        X_out = X.copy()\n",
      "        \n",
      "        # extracts various date-related features\n",
      "        dtt = pd.to_datetime(X_out.Dates)\n",
      "        \n",
      "        X_out[\"hour_delta\"] = add_delta(dtt, \"h\") # hour since start, 0 to 108263\n",
      "        X_out[\"day_delta\"] = add_delta(dtt, \"D\") # day since start, 0 to 4510\n",
      "        X_out[\"week_delta\"] = add_delta(dtt, \"W\") # week since start, 0 to 644\n",
      "        X_out[\"month_delta\"] = add_delta(dtt, \"M\") # month since start, 0 to 148\n",
      "        X_out[\"year_delta\"] = add_delta(dtt, \"Y\") # year since start, 0 to 12\n",
      "        \n",
      "        X_out[\"hour_of_day\"] = dtt.dt.hour # 0 to 23\n",
      "        X_out[\"day_of_week\"] = dtt.dt.dayofweek # 0 to 7, note day name is already DayOfWeek\n",
      "        X_out[\"day_of_month\"] = dtt.dt.day # 1 to 31\n",
      "        X_out[\"day_of_year\"] = dtt.dt.dayofyear # 1 to 365\n",
      "        X_out[\"week_of_year\"] = dtt.dt.week # 2 to 52\n",
      "        X_out[\"month_of_year\"] = dtt.dt.month # 1 to 12\n",
      "        X_out[\"quarter_of_year\"] = dtt.dt.quarter # 1 to 4\n",
      "        X_out[\"year\"] = dtt.dt.year # 2003 to 2015\n",
      "        \n",
      "        X_out[\"is_weekend\"] = dtt.dt.dayofweek // 5 # 1 if sat or sun, 0 otherwise\n",
      "        X_out[\"is_holiday\"] = calc_is_holiday(dtt) # 1 if holiday, 0 otherwise\n",
      "        \n",
      "        # calculate cyclical values for hours, etc\n",
      "        # http://blog.davidkaleko.com/feature-engineering-cyclical-features.html\n",
      "        X_out[\"hour_of_day_sin\"] = np.round( np.sin(dtt.dt.hour * (2. * np.pi / 24)), 3)\n",
      "        X_out[\"hour_of_day_cos\"] = np.round( np.cos(dtt.dt.hour * (2. * np.pi / 24)), 3)\n",
      "        \n",
      "        X_out[\"day_of_week_sin\"] = np.round( np.sin(dtt.dt.dayofweek * (2. * np.pi / 7)), 3)\n",
      "        X_out[\"day_of_week_cos\"] = np.round( np.cos(dtt.dt.dayofweek * (2. * np.pi / 7)), 3)\n",
      "        \n",
      "        X_out[\"month_of_year_sin\"] = np.round( np.sin((dtt.dt.month - 1) * (2. * np.pi / 12)), 3)\n",
      "        X_out[\"month_of_year_cos\"] = np.round( np.cos((dtt.dt.month - 1) * (2. * np.pi / 12)), 3)\n",
      "        \n",
      "        X_out[\"is_latenight\"] = calc_is_latenight(dtt) # 1 if after 8 pm and before 6 am, 0 otherwise\n",
      "        \n",
      "        # TODO calculate police shifts? apparently its not regularly-spaced shifts\n",
      "        \n",
      "        # TODO calculate address-based features, such as street, intersection, etc\n",
      "        \n",
      "        # TODO calculate distance from hotspots of crime\n",
      "        \n",
      "        return X_out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(SFCCTransformer)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def prep_submissions(predsproba, categories):\n",
      "    \"\"\"\n",
      "    Helper function to prepare the raw predsproba array into a panda with the correct column headers and an index\n",
      "    \"\"\"\n",
      "    cols = np.sort(pd.unique(categories))\n",
      "    submissions = pd.DataFrame(data = predsproba, columns = cols)\n",
      "    \n",
      "    # rounds any floats to less precision\n",
      "    submissions= submissions[cols].round(2)\n",
      "    \n",
      "    # adds an Id column\n",
      "    idx = np.arange(0, len(predsproba))\n",
      "    submissions.insert(loc = 0, column = \"Id\", value = idx.tolist())\n",
      "    return(submissions)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(prep_submissions)\n",
    "print(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
