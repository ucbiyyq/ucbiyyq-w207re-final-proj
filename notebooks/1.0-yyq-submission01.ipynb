{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 01 for San Francisco Crime Classification\n",
    "Yang Yang Qian\n",
    "\n",
    "https://www.kaggle.com/c/sf-crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from plotnine import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.features.build_features import DataFrameSelector, SFCCTransformer, print_summary\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv(\"../data/raw/train.csv.zip\", compression=\"zip\")\n",
    "test_pd = pd.read_csv(\"../data/raw/test.csv.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some more features using our custom transformer\n",
    "sfcc = SFCCTransformer()\n",
    "pipe = Pipeline([\n",
    "    (\"transformer\", sfcc)\n",
    "])\n",
    "train_pd = pipe.transform(train_pd)\n",
    "test_pd = pipe.transform(test_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 800k records in both train and test data sets. The train data set has the Category, Descript, and Resolution columns, which are missing from the test data set.\n",
    "\n",
    "We will need to use the test data set to generate the submission to Kaggle. Thus, we need to split the train data set into train and dev sets for training our classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 9)\n",
      "(884262, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_pd.shape)\n",
    "print(test_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates        Category                  Descript  DayOfWeek  \\\n",
       "0  2015-05-13 23:53:00        WARRANTS            WARRANT ARREST  Wednesday   \n",
       "1  2015-05-13 23:53:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "2  2015-05-13 23:33:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "\n",
       "  PdDistrict      Resolution                    Address           X          Y  \n",
       "0   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST -122.425892  37.774599  \n",
       "1   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST -122.425892  37.774599  \n",
       "2   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST -122.424363  37.800414  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                Dates DayOfWeek PdDistrict                  Address  \\\n",
       "0   0  2015-05-10 23:59:00    Sunday    BAYVIEW  2000 Block of THOMAS AV   \n",
       "1   1  2015-05-10 23:51:00    Sunday    BAYVIEW       3RD ST / REVERE AV   \n",
       "2   2  2015-05-10 23:50:00    Sunday   NORTHERN   2000 Block of GOUGH ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  \n",
       "1 -122.391523  37.732432  \n",
       "2 -122.426002  37.792212  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendicies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class DataFrameSelector(BaseEstimator, TransformerMixin): \n",
      "    \"\"\"\n",
      "    Simple helper class, meant make it easier to use Pandas \n",
      "    along with sklearn Pipeline. Create and initate with a \n",
      "    list of features, then when the pipeline transform function\n",
      "    is called, will return a Numpy array of the features.\n",
      "    \n",
      "    See Chap 2 transformation pipelines\n",
      "    \n",
      "    Example:\n",
      "        train_pd = pd.read_csv(\"data.csv\")\n",
      "        num_features = [\"X\", \"Y\"]\n",
      "        num_pipeline = Pipeline([\n",
      "            (\"selector\", DataFrameSelector(num_features))\n",
      "        ])\n",
      "        train_prepared = num_pipeline.transform(train_pd)\n",
      "        \n",
      "    \"\"\"\n",
      "    def __init__(self, attribute_names): \n",
      "        self.attribute_names = attribute_names \n",
      "        \n",
      "    def fit(self, X, y = None): \n",
      "        return self \n",
      "    \n",
      "    def transform(self, X): \n",
      "        return X[self.attribute_names].values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(DataFrameSelector)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFCCTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SFCCTransformer(BaseEstimator, TransformerMixin):\n",
      "    \"\"\"\n",
      "    Helper class for our SanFrancisco Crime Classification project.\n",
      "    \n",
      "    Centralizes transformation logic, and make it easier to use\n",
      "    transformations with Pandas, Pipeline, and gscv. Note, meant to transform\n",
      "    Pandas into Pandas.\n",
      "    \n",
      "    Should use in conjunction with DataFrameSelector and one hot encoders.\n",
      "    \n",
      "    See Chap 2 custom transformers\n",
      "    \n",
      "    \"\"\"\n",
      "    def __init__(self, holiday_calendar = USFederalHolidayCalendar()):\n",
      "        self.holiday_calendar = holiday_calendar\n",
      "        \n",
      "    def fit(self, X, y = None):\n",
      "        return self # no fitting\n",
      "    \n",
      "    def transform(self, X, y = None):\n",
      "        \n",
      "        def add_delta(dtt, delta):\n",
      "            \"\"\"\n",
      "            helper funciton, given a Series of dates, \n",
      "            returns Series of delta since the mininum date\n",
      "            \n",
      "            see Linda's baseline code\n",
      "            \"\"\"\n",
      "            res = (dtt - dtt.min()) / np.timedelta64(1, delta)\n",
      "            res = np.floor(res).astype(\"int\")\n",
      "            return res\n",
      "        \n",
      "        def calc_is_holiday(dtt):\n",
      "            \"\"\"\n",
      "            Helper function, given Series dates, \n",
      "            returns Series of 1 if date is holiday, 0 otherwise\n",
      "            \n",
      "            https://stackoverflow.com/questions/29688899/pandas-checking-if-a-date-is-a-holiday-and-assigning-boolean-value\n",
      "            \"\"\"\n",
      "            dt = dtt.dt.date\n",
      "            holidays = self.holiday_calendar.holidays(start = dt.min(), end = dt.max()).date\n",
      "            res = dt.isin(holidays).astype(\"int\")\n",
      "            return res\n",
      "        \n",
      "        # extracts various date-related features\n",
      "        dtt = pd.to_datetime(X.Dates)\n",
      "        \n",
      "        X[\"hour_delta\"] = add_delta(dtt, \"h\") # hour since start, 0 to 108263\n",
      "        X[\"day_delta\"] = add_delta(dtt, \"D\") # day since start, 0 to 4510\n",
      "        X[\"week_delta\"] = add_delta(dtt, \"W\") # week since start, 0 to 644\n",
      "        X[\"month_delta\"] = add_delta(dtt, \"M\") # month since start, 0 to 148\n",
      "        X[\"year_delta\"] = add_delta(dtt, \"Y\") # year since start, 0 to 12\n",
      "        \n",
      "        X[\"hour_of_day\"] = dtt.dt.hour # 0 to 23\n",
      "        X[\"day_of_week\"] = dtt.dt.dayofweek # 0 to 7, note day name is already DayOfWeek\n",
      "        X[\"day_of_month\"] = dtt.dt.day # 1 to 31\n",
      "        X[\"day_of_year\"] = dtt.dt.dayofyear # 1 to 365\n",
      "        X[\"week_of_year\"] = dtt.dt.week # 2 to 52\n",
      "        X[\"month_of_year\"] = dtt.dt.month # 1 to 12\n",
      "        X[\"quarter_of_year\"] = dtt.dt.quarter # 1 to 4\n",
      "        X[\"year\"] = dtt.dt.year # 2003 to 2015\n",
      "        \n",
      "        X[\"is_weekend\"] = dtt.dt.dayofweek // 5 # 1 if sat or sun, 0 otherwise\n",
      "        X[\"is_holiday\"] = calc_is_holiday(dtt) # 1 if holiday, 0 otherwise\n",
      "        \n",
      "        # calculate cyclical values for hours, etc\n",
      "        # http://blog.davidkaleko.com/feature-engineering-cyclical-features.html\n",
      "        X[\"hour_of_day_sin\"] = np.round( np.sin(dtt.dt.hour * (2. * np.pi / 24)), 3)\n",
      "        X[\"hour_of_day_cos\"] = np.round( np.cos(dtt.dt.hour * (2. * np.pi / 24)), 3)\n",
      "        \n",
      "        X[\"day_of_week_sin\"] = np.round( np.sin(dtt.dt.dayofweek * (2. * np.pi / 7)), 3)\n",
      "        X[\"day_of_week_cos\"] = np.round( np.cos(dtt.dt.dayofweek * (2. * np.pi / 7)), 3)\n",
      "        \n",
      "        X[\"month_of_year_sin\"] = np.round( np.sin((dtt.dt.month - 1) * (2. * np.pi / 12)), 3)\n",
      "        X[\"month_of_year_cos\"] = np.round( np.cos((dtt.dt.month - 1) * (2. * np.pi / 12)), 3)\n",
      "        \n",
      "        # TODO calculate police shifts? apparently its not regularly-spaced shifts\n",
      "        \n",
      "        \n",
      "        \n",
      "        return X\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(SFCCTransformer)\n",
    "print(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
