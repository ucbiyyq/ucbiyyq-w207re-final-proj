{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 01 for San Francisco Crime Classification\n",
    "Yang Yang Qian\n",
    "\n",
    "https://www.kaggle.com/c/sf-crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.features.build_features import DataFrameSelector, SFCCTransformer, print_summary, prep_submissions\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv(\"../data/raw/train.csv.zip\", compression=\"zip\")\n",
    "test_pd = pd.read_csv(\"../data/raw/test.csv.zip\", compression=\"zip\")\n",
    "sample_submissions = pd.read_csv(\"../data/raw/sampleSubmission.csv.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some more features using our custom transformer\n",
    "sfcc = SFCCTransformer()\n",
    "pipe = Pipeline([\n",
    "    (\"transformer\", sfcc)\n",
    "])\n",
    "train_pd = pipe.transform(train_pd)\n",
    "test_pd = pipe.transform(test_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have about 800k records in both train and test data sets. The train data set has the Category, Descript, and Resolution columns, which are missing from the test data set.\n",
    "\n",
    "We will need to use the test data set to generate the submission to Kaggle.\n",
    "\n",
    "TODO add more plots and EDA from scratch EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 31)\n",
      "(884262, 29)\n"
     ]
    }
   ],
   "source": [
    "print(train_pd.shape)\n",
    "print(test_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>hour_delta</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>hour_of_day_sin</th>\n",
       "      <th>hour_of_day_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>month_of_year_sin</th>\n",
       "      <th>month_of_year_cos</th>\n",
       "      <th>is_latenight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>108263</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>108263</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>108263</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates        Category                  Descript  DayOfWeek  \\\n",
       "0  2015-05-13 23:53:00        WARRANTS            WARRANT ARREST  Wednesday   \n",
       "1  2015-05-13 23:53:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "2  2015-05-13 23:33:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "\n",
       "  PdDistrict      Resolution                    Address           X  \\\n",
       "0   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST -122.425892   \n",
       "1   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST -122.425892   \n",
       "2   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST -122.424363   \n",
       "\n",
       "           Y  hour_delta  ...  year  is_weekend  is_holiday  hour_of_day_sin  \\\n",
       "0  37.774599      108263  ...  2015           0           0           -0.259   \n",
       "1  37.774599      108263  ...  2015           0           0           -0.259   \n",
       "2  37.800414      108263  ...  2015           0           0           -0.259   \n",
       "\n",
       "   hour_of_day_cos  day_of_week_sin  day_of_week_cos  month_of_year_sin  \\\n",
       "0            0.966            0.975           -0.223              0.866   \n",
       "1            0.966            0.975           -0.223              0.866   \n",
       "2            0.966            0.975           -0.223              0.866   \n",
       "\n",
       "   month_of_year_cos  is_latenight  \n",
       "0               -0.5             1  \n",
       "1               -0.5             1  \n",
       "2               -0.5             1  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>hour_delta</th>\n",
       "      <th>day_delta</th>\n",
       "      <th>week_delta</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>hour_of_day_sin</th>\n",
       "      <th>hour_of_day_cos</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>month_of_year_sin</th>\n",
       "      <th>month_of_year_cos</th>\n",
       "      <th>is_latenight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "      <td>108311</td>\n",
       "      <td>4512</td>\n",
       "      <td>644</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "      <td>108311</td>\n",
       "      <td>4512</td>\n",
       "      <td>644</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "      <td>108311</td>\n",
       "      <td>4512</td>\n",
       "      <td>644</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.966</td>\n",
       "      <td>-0.782</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                Dates DayOfWeek PdDistrict                  Address  \\\n",
       "0   0  2015-05-10 23:59:00    Sunday    BAYVIEW  2000 Block of THOMAS AV   \n",
       "1   1  2015-05-10 23:51:00    Sunday    BAYVIEW       3RD ST / REVERE AV   \n",
       "2   2  2015-05-10 23:50:00    Sunday   NORTHERN   2000 Block of GOUGH ST   \n",
       "\n",
       "            X          Y  hour_delta  day_delta  week_delta  ...  year  \\\n",
       "0 -122.399588  37.735051      108311       4512         644  ...  2015   \n",
       "1 -122.391523  37.732432      108311       4512         644  ...  2015   \n",
       "2 -122.426002  37.792212      108311       4512         644  ...  2015   \n",
       "\n",
       "   is_weekend  is_holiday  hour_of_day_sin  hour_of_day_cos  day_of_week_sin  \\\n",
       "0           1           0           -0.259            0.966           -0.782   \n",
       "1           1           0           -0.259            0.966           -0.782   \n",
       "2           1           0           -0.259            0.966           -0.782   \n",
       "\n",
       "   day_of_week_cos  month_of_year_sin  month_of_year_cos  is_latenight  \n",
       "0            0.623              0.866               -0.5             1  \n",
       "1            0.623              0.866               -0.5             1  \n",
       "2            0.623              0.866               -0.5             1  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 31)\n",
      "(878049,)\n"
     ]
    }
   ],
   "source": [
    "# shuffles the train data\n",
    "# note, we don't need a dev set since we are using cross validation\n",
    "train_data = train_pd.sample(frac=1, random_state = 0)\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "# gets the train labels\n",
    "train_labels = train_data[\"Category\"]\n",
    "\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.270):\n",
      "{'knn__n_neighbors': 26, 'selector__attribute_names': ['X', 'Y']}\n"
     ]
    }
   ],
   "source": [
    "# pipeline to prep our data and fit classifiers\n",
    "selector = DataFrameSelector([\"X\", \"Y\"])\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"selector\", selector)\n",
    "    ,(\"knn\", knn)\n",
    "])\n",
    "\n",
    "# TODO add more classifier types and attributes, use list of dicts for alt paths\n",
    "# TODO figure out how to add ensembles to this, maybe with soft voting?\n",
    "# TODO SVM, knn, random forest, etc\n",
    "param_grid = {\n",
    "    \"selector__attribute_names\": [\n",
    "        [\"X\", \"Y\"]\n",
    "        , [\"X\", \"Y\", \"is_latenight\"]\n",
    "#         ,[\"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "#         ,[\"X\", \"Y\", \"hour_of_day_sin\", \"hour_of_day_cos\"]\n",
    "    ]\n",
    "    ,\"knn__n_neighbors\": [3, 16, 26]\n",
    "}\n",
    "\n",
    "# TODO figure out how to do stratified kfold by category\n",
    "# TODO figure out how to add bagging to this\n",
    "search = GridSearchCV(pipe, param_grid, iid = True, cv = 3, return_train_score = False)\n",
    "\n",
    "_ = search.fit(train_data, train_labels)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.11538462 0.         0.         0.         0.\n",
      "  0.         0.03846154 0.         0.03846154 0.         0.\n",
      "  0.         0.03846154 0.         0.         0.         0.\n",
      "  0.         0.19230769 0.         0.07692308 0.         0.\n",
      "  0.         0.         0.03846154 0.         0.         0.\n",
      "  0.         0.         0.07692308 0.         0.         0.11538462\n",
      "  0.15384615 0.11538462 0.        ]\n",
      " [0.         0.15384615 0.         0.         0.         0.\n",
      "  0.         0.03846154 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.15384615 0.03846154\n",
      "  0.         0.03846154 0.         0.46153846 0.         0.\n",
      "  0.         0.03846154 0.         0.         0.         0.\n",
      "  0.         0.         0.07692308 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.03846154 0.         0.         0.19230769 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23076923 0.\n",
      "  0.         0.         0.07692308 0.03846154 0.         0.\n",
      "  0.         0.         0.         0.03846154 0.         0.\n",
      "  0.         0.         0.03846154 0.         0.         0.07692308\n",
      "  0.26923077 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# makes predictions against our test data using our best classifier\n",
    "predsproba = search.best_estimator_.predict_proba(test_pd)\n",
    "print(predsproba[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884262, 40)\n",
      "   Id  ARSON  ASSAULT  BAD CHECKS  BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
      "0   0    0.0     0.12         0.0      0.0      0.00                 0.0   \n",
      "1   1    0.0     0.15         0.0      0.0      0.00                 0.0   \n",
      "2   2    0.0     0.04         0.0      0.0      0.19                 0.0   \n",
      "\n",
      "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS  ...  \\\n",
      "0                          0.0           0.04          0.0  ...   \n",
      "1                          0.0           0.04          0.0  ...   \n",
      "2                          0.0           0.00          0.0  ...   \n",
      "\n",
      "   SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY  SUICIDE  SUSPICIOUS OCC  TREA  \\\n",
      "0                        0.0              0.0      0.0            0.08   0.0   \n",
      "1                        0.0              0.0      0.0            0.08   0.0   \n",
      "2                        0.0              0.0      0.0            0.04   0.0   \n",
      "\n",
      "   TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  WEAPON LAWS  \n",
      "0       0.0       0.12           0.15      0.12          0.0  \n",
      "1       0.0       0.00           0.00      0.00          0.0  \n",
      "2       0.0       0.08           0.27      0.00          0.0  \n",
      "\n",
      "[3 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# converts predicted probabilities into submission panda\n",
    "submissions = prep_submissions(predsproba, train_pd.Category)\n",
    "\n",
    "print(submissions.shape)\n",
    "print(submissions.head(3))\n",
    "\n",
    "# checks submission has the correct number of rows and columns\n",
    "assert(sample_submissions.shape[0] == submissions.shape[0])\n",
    "assert(sample_submissions.shape[1] == submissions.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save submissions to disk\n",
    "submissions.to_csv(\"../data/processed/submission.csv.gz\", index = False, compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendicies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class DataFrameSelector(BaseEstimator, TransformerMixin): \n",
      "    \"\"\"\n",
      "    Simple helper class, meant make it easier to use Pandas \n",
      "    along with sklearn Pipeline. Create and initate with a \n",
      "    list of features, then when the pipeline transform function\n",
      "    is called, will return a Numpy array of the features.\n",
      "    \n",
      "    See Chap 2 transformation pipelines\n",
      "    \n",
      "    Example:\n",
      "        train_pd = pd.read_csv(\"data.csv\")\n",
      "        num_features = [\"X\", \"Y\"]\n",
      "        num_pipeline = Pipeline([\n",
      "            (\"selector\", DataFrameSelector(num_features))\n",
      "        ])\n",
      "        train_prepared = num_pipeline.transform(train_pd)\n",
      "        \n",
      "    \"\"\"\n",
      "    def __init__(self, attribute_names): \n",
      "        self.attribute_names = attribute_names \n",
      "        \n",
      "    def fit(self, X, y = None): \n",
      "        return self \n",
      "    \n",
      "    def transform(self, X): \n",
      "        return X[self.attribute_names].values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(DataFrameSelector)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFCCTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SFCCTransformer(BaseEstimator, TransformerMixin):\n",
      "    \"\"\"\n",
      "    Helper class for our SanFrancisco Crime Classification project.\n",
      "    \n",
      "    Centralizes transformation logic, and make it easier to use\n",
      "    transformations with Pandas, Pipeline, and gscv. Note, meant to transform\n",
      "    Pandas into Pandas.\n",
      "    \n",
      "    Should use in conjunction with DataFrameSelector and one hot encoders.\n",
      "    \n",
      "    See Chap 2 custom transformers\n",
      "    \n",
      "    \"\"\"\n",
      "    def __init__(self, holiday_calendar = USFederalHolidayCalendar(), latitude_outlier = 50):\n",
      "        self.holiday_calendar = holiday_calendar\n",
      "        self.latitude_outlier = latitude_outlier\n",
      "        \n",
      "    def fit(self, X, y = None):\n",
      "        return self # no fitting\n",
      "    \n",
      "    def transform(self, X, y = None):\n",
      "        \n",
      "        def add_delta(dtt, delta):\n",
      "            \"\"\"\n",
      "            helper funciton, given a Series of dates, \n",
      "            returns Series of delta since the mininum date\n",
      "            \n",
      "            see Linda's baseline code\n",
      "            \"\"\"\n",
      "            res = (dtt - dtt.min()) / np.timedelta64(1, delta)\n",
      "            res = np.floor(res).astype(\"int\")\n",
      "            return res\n",
      "        \n",
      "        def calc_is_holiday(dtt):\n",
      "            \"\"\"\n",
      "            Helper function, given Series dates, \n",
      "            returns Series of 1 if date is holiday, 0 otherwise\n",
      "            \n",
      "            https://stackoverflow.com/questions/29688899/pandas-checking-if-a-date-is-a-holiday-and-assigning-boolean-value\n",
      "            \"\"\"\n",
      "            dt = dtt.dt.date\n",
      "            holidays = self.holiday_calendar.holidays(start = dt.min(), end = dt.max()).date\n",
      "            res = dt.isin(holidays).astype(\"int\")\n",
      "            return res\n",
      "        \n",
      "        def calc_is_latenight(dtt):\n",
      "            hrs = dtt.dt.hour\n",
      "            res = np.ones(shape = hrs.shape)\n",
      "            res[(hrs > 7) & (hrs < 20)] = 0\n",
      "            res = res.astype(\"int\")\n",
      "            return res\n",
      "        \n",
      "        # creates a copy of the input dataframe\n",
      "        X_out = X.copy()\n",
      "        \n",
      "        # extracts various date-related features\n",
      "        dtt = pd.to_datetime(X_out.Dates)\n",
      "        \n",
      "        X_out[\"hour_delta\"] = add_delta(dtt, \"h\") # hour since start, 0 to 108263\n",
      "        X_out[\"day_delta\"] = add_delta(dtt, \"D\") # day since start, 0 to 4510\n",
      "        X_out[\"week_delta\"] = add_delta(dtt, \"W\") # week since start, 0 to 644\n",
      "        X_out[\"month_delta\"] = add_delta(dtt, \"M\") # month since start, 0 to 148\n",
      "        X_out[\"year_delta\"] = add_delta(dtt, \"Y\") # year since start, 0 to 12\n",
      "        \n",
      "        X_out[\"hour_of_day\"] = dtt.dt.hour # 0 to 23\n",
      "        X_out[\"day_of_week\"] = dtt.dt.dayofweek # 0 to 7, note day name is already DayOfWeek\n",
      "        X_out[\"day_of_month\"] = dtt.dt.day # 1 to 31\n",
      "        X_out[\"day_of_year\"] = dtt.dt.dayofyear # 1 to 365\n",
      "        X_out[\"week_of_year\"] = dtt.dt.week # 2 to 52\n",
      "        X_out[\"month_of_year\"] = dtt.dt.month # 1 to 12\n",
      "        X_out[\"quarter_of_year\"] = dtt.dt.quarter # 1 to 4\n",
      "        X_out[\"year\"] = dtt.dt.year # 2003 to 2015\n",
      "        \n",
      "        X_out[\"is_weekend\"] = dtt.dt.dayofweek // 5 # 1 if sat or sun, 0 otherwise\n",
      "        X_out[\"is_holiday\"] = calc_is_holiday(dtt) # 1 if holiday, 0 otherwise\n",
      "        \n",
      "        # calculate cyclical values for hours, etc\n",
      "        # http://blog.davidkaleko.com/feature-engineering-cyclical-features.html\n",
      "        X_out[\"hour_of_day_sin\"] = np.round( np.sin(dtt.dt.hour * (2. * np.pi / 24)), 3)\n",
      "        X_out[\"hour_of_day_cos\"] = np.round( np.cos(dtt.dt.hour * (2. * np.pi / 24)), 3)\n",
      "        \n",
      "        X_out[\"day_of_week_sin\"] = np.round( np.sin(dtt.dt.dayofweek * (2. * np.pi / 7)), 3)\n",
      "        X_out[\"day_of_week_cos\"] = np.round( np.cos(dtt.dt.dayofweek * (2. * np.pi / 7)), 3)\n",
      "        \n",
      "        X_out[\"month_of_year_sin\"] = np.round( np.sin((dtt.dt.month - 1) * (2. * np.pi / 12)), 3)\n",
      "        X_out[\"month_of_year_cos\"] = np.round( np.cos((dtt.dt.month - 1) * (2. * np.pi / 12)), 3)\n",
      "        \n",
      "        X_out[\"is_latenight\"] = calc_is_latenight(dtt) # 1 if after 8 pm and before 6 am, 0 otherwise\n",
      "        \n",
      "        # TODO calculate police shifts? apparently its not regularly-spaced shifts\n",
      "        \n",
      "        # TODO calculate address-based features, such as street, intersection, etc\n",
      "        \n",
      "        # TODO calculate distance from hotspots of crime\n",
      "        \n",
      "        return X_out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(SFCCTransformer)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def prep_submissions(predsproba, categories):\n",
      "    \"\"\"\n",
      "    Helper function to prepare the raw predsproba array into a panda with the correct column headers and an index\n",
      "    \"\"\"\n",
      "    cols = np.sort(pd.unique(categories))\n",
      "    submissions = pd.DataFrame(data = predsproba, columns = cols)\n",
      "    \n",
      "    # rounds any floats to less precision\n",
      "    submissions= submissions[cols].round(2)\n",
      "    \n",
      "    # adds an Id column\n",
      "    idx = np.arange(0, len(predsproba))\n",
      "    submissions.insert(loc = 0, column = \"Id\", value = idx.tolist())\n",
      "    return(submissions)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = inspect.getsource(prep_submissions)\n",
    "print(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
