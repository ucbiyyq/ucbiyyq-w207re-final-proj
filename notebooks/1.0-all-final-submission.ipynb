{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Final for San Francisco Crime Classification\n",
    "\n",
    "MIDS W207 final project\n",
    "\n",
    "DATASCI W207 Applied Machine Learning, Section 6\n",
    "\n",
    "\n",
    "*TODO insert explanation of what we're trying to do. see Arthur's notebooks for comments*\n",
    "\n",
    "\n",
    "Kaggle \n",
    "\n",
    "* https://www.kaggle.com/c/sf-crime\n",
    "\n",
    "Project members:\n",
    "\n",
    "* Linda Lima\n",
    "* Arthur Dong\n",
    "* Yang Yang Qian\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "import inspect\n",
    "\n",
    "# we will using seaborn for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# we will also need our custom data transformers\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import src.features.build_features as bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv(\"../data/raw/train.csv.zip\", compression=\"zip\")\n",
    "test_pd = pd.read_csv(\"../data/raw/test.csv.zip\", compression=\"zip\")\n",
    "sample_submissions = pd.read_csv(\"../data/raw/sampleSubmission.csv.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA, Feature Engineering, and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffles the train and test dataframes\n",
    "# we are not using a dev set, because we will using cross validation for model selection\n",
    "train_data, train_labels, _, _, test_data, test_ids = bf.prep_data(train_pd, test_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y']\n",
      "(878049, 6)\n",
      "<class 'pandas.core.series.Series'>\n",
      "(878049,)\n",
      "================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y']\n",
      "(884262, 6)\n",
      "<class 'pandas.core.series.Series'>\n",
      "(884262,)\n"
     ]
    }
   ],
   "source": [
    "print(\"================\")\n",
    "print(type(train_data))\n",
    "print(list(train_data.columns))\n",
    "print(train_data.shape)\n",
    "print(type(train_labels))\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(\"================\")\n",
    "print(type(test_data))\n",
    "print(list(test_data.columns))\n",
    "print(test_data.shape)\n",
    "print(type(test_ids))\n",
    "print(test_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need lots of plots and document some of the insights, \n",
    "# copy the interesting stuff from EDA notebook and other scratch notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for:\n",
    "# standard SFCCTransformer\n",
    "# Address transformer\n",
    "# Cluster transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "\n",
    "# using PCA, projecting to number of components\n",
    "# L1 then L2\n",
    "# Random Forest feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To try for models?\n",
    "# knn\n",
    "# logistic Regression\n",
    "# random forest\n",
    "# svm?\n",
    "# Gradient boosted\n",
    "# MLP\n",
    "\n",
    "# error detection\n",
    "# test for overfit, plotting train vs dev acuracy on some metric, i.e. complexity or number of records vs cv-score\n",
    "\n",
    "# probability array\n",
    "# combine with soft voting\n",
    "\n",
    "# submission list???\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts predicted probabilities into submission panda\n",
    "submissions = prep_submissions(predsproba, train_pd.Category)\n",
    "\n",
    "print(submissions.shape)\n",
    "print(submissions.head(3))\n",
    "\n",
    "# checks submission has the correct number of rows and columns\n",
    "assert(sample_submissions.shape[0] == submissions.shape[0])\n",
    "assert(sample_submissions.shape[1] == submissions.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save submissions to disk\n",
    "submissions.to_csv(\"../data/processed/submission.csv.gz\", index = False, compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introspect some code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
