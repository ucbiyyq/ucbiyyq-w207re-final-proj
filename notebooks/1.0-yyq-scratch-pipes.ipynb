{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "test notebook to figure out how sklearn pipeslines work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads data\n",
    "train_pd = pd.read_csv(\"../data/raw/train.csv.zip\", compression=\"zip\")\n",
    "test_pd = pd.read_csv(\"../data/raw/test.csv.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the usual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "shuffled = train_pd.sample(frac=1)\n",
    "split = round(train_pd.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# splits the labels from the features\n",
    "features = [\"X\", \"Y\"]\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data[\"Category\"]\n",
    "\n",
    "dev_features = dev_data[features]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "test_features = test_pd[features]\n",
    "\n",
    "# does a silly transformation\n",
    "def silly(df):\n",
    "    return df.X + df.Y\n",
    "\n",
    "train_features[\"Z\"] = silly(train_features)\n",
    "dev_features[\"Z\"] = silly(dev_features)\n",
    "test_features[\"Z\"] = silly(test_features)\n",
    "\n",
    "# uses a simple knn\n",
    "clsfr = KNeighborsClassifier(n_neighbors = 3)\n",
    "clsfr.fit(train_features, train_labels)\n",
    "\n",
    "# checks basic accuracy\n",
    "score = clsfr.score(dev_features, dev_labels)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "shuffled = train_pd.sample(frac=1)\n",
    "split = round(train_pd.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# splits the labels from the features\n",
    "features = [\"X\", \"Y\"]\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data[\"Category\"]\n",
    "\n",
    "dev_features = dev_data[features]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "test_features = test_pd[features]\n",
    "\n",
    "# see https://stackoverflow.com/questions/33091376/python-what-is-exactly-sklearn-pipeline-pipeline\n",
    "\n",
    "class MyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass # nothing to init\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self # no fitting\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        def silly(df):\n",
    "            return df.X + df.Y\n",
    "        X[\"Z\"] = silly(X)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "# use pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('silly', MyTransformer()),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors = 3)),\n",
    "])\n",
    "_ = pipeline.fit(train_features, train_labels)\n",
    "# Now evaluate all steps on test set\n",
    "score = pipeline.score(dev_features, dev_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pipelines on both numeric and categorical features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-122.41967178   37.76505012    0.            0.            0.\n",
      "    0.            0.            0.            1.        ]\n",
      "[-122.40763352   37.78418935    0.            0.            0.\n",
      "    0.            0.            0.            1.        ]\n",
      "(800, 9)\n",
      "(800,)\n",
      "[-122.41765068   37.78801585    0.            1.            0.\n",
      "    0.            0.            0.            0.        ]\n",
      "[-122.4191831    37.78309982    0.            1.            0.\n",
      "    0.            0.            0.            0.        ]\n",
      "(199, 9)\n",
      "(199,)\n",
      "0.12562814070351758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# subsets data to make next steps faster\n",
    "train_subset = train_pd.sample(n = 1000, random_state = 0)\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "# TODO replace with sklearn's stratified splitter???\n",
    "shuffled = train_subset.sample(frac=1)\n",
    "split = round(train_subset.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# TODO is this the best way to separate out the labels from the features???\n",
    "train_labels = train_data[\"Category\"]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "# see Chap 2 transformation pipelines\n",
    "\n",
    "class DataFrameSelector( BaseEstimator, TransformerMixin): \n",
    "    def __init__( self, attribute_names): \n",
    "        self.attribute_names = attribute_names \n",
    "        \n",
    "    def fit( self, X, y = None): \n",
    "        return self \n",
    "    \n",
    "    def transform( self, X): \n",
    "        return X[ self.attribute_names].values\n",
    "\n",
    "    \n",
    "num_features = [\"X\", \"Y\"]\n",
    "cat_features = [\"DayOfWeek\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(num_features))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(cat_features)),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list = [\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "train_prepared = full_pipeline.fit_transform(train_data)\n",
    "print(train_prepared[0])\n",
    "print(train_prepared[400])\n",
    "print(train_prepared.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "dev_prepared = full_pipeline.fit_transform(dev_data)\n",
    "print(dev_prepared[0])\n",
    "print(dev_prepared[50])\n",
    "print(dev_prepared.shape)\n",
    "print(dev_labels.shape)\n",
    "\n",
    "# TODO how to get the list of learned encodings???\n",
    "# print(cat_pipeline)\n",
    "# print(full_pipeline)\n",
    "\n",
    "\n",
    "# reuse pipeline code from previous section to classify\n",
    "clf_pipeline = Pipeline([\n",
    "    ('clf', KNeighborsClassifier(n_neighbors = 3))\n",
    "])\n",
    "\n",
    "_ = clf_pipeline.fit(train_prepared, train_labels)\n",
    "# Now evaluate all steps on test set\n",
    "score = clf_pipeline.score(dev_prepared, dev_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pipelines and gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-122.40114294   37.78900115    1.            0.            0.\n",
      "    0.            0.            0.            0.        ]\n",
      "[-122.44471296   37.77130219    0.            0.            0.\n",
      "    0.            0.            0.            1.        ]\n",
      "(800, 9)\n",
      "(800,)\n",
      "[-122.41095525   37.78413995    0.            0.            0.\n",
      "    1.            0.            0.            0.        ]\n",
      "[-122.40742204   37.76448809    0.            0.            1.\n",
      "    0.            0.            0.            0.        ]\n",
      "(199, 9)\n",
      "(199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangyq\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.165):\n",
      "{'knn__n_neighbors': 23}\n",
      "0.19095477386934673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# subsets data to make next steps faster\n",
    "train_subset = train_pd.sample(n = 1000, random_state = 0)\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "# TODO replace with sklearn's stratified splitter???\n",
    "shuffled = train_subset.sample(frac=1)\n",
    "split = round(train_subset.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# TODO is this the best way to separate out the labels from the features???\n",
    "train_labels = train_data[\"Category\"]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "# see Chap 2 transformation pipelines\n",
    "\n",
    "class DataFrameSelector( BaseEstimator, TransformerMixin): \n",
    "    def __init__( self, attribute_names): \n",
    "        self.attribute_names = attribute_names \n",
    "        \n",
    "    def fit( self, X, y = None): \n",
    "        return self \n",
    "    \n",
    "    def transform( self, X): \n",
    "        return X[ self.attribute_names].values\n",
    "\n",
    "    \n",
    "num_features = [\"X\", \"Y\"]\n",
    "cat_features = [\"DayOfWeek\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(num_features))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(cat_features)),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list = [\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "train_prepared = full_pipeline.fit_transform(train_data)\n",
    "print(train_prepared[0])\n",
    "print(train_prepared[400])\n",
    "print(train_prepared.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "dev_prepared = full_pipeline.fit_transform(dev_data)\n",
    "print(dev_prepared[0])\n",
    "print(dev_prepared[50])\n",
    "print(dev_prepared.shape)\n",
    "print(dev_labels.shape)\n",
    "\n",
    "# TODO how to get the list of learned encodings???\n",
    "# print(cat_pipeline)\n",
    "# print(full_pipeline)\n",
    "\n",
    "\n",
    "# reuse pipeline code from previous section to classify\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf_pipeline = Pipeline(steps = [\n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "# see https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 9, 17, 23]\n",
    "}\n",
    "search = GridSearchCV(clf_pipeline, param_grid, iid = False, cv = 5, return_train_score = False)\n",
    "\n",
    "_ = search.fit(train_prepared, train_labels)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "# Now evaluate all steps on test set\n",
    "score = search.score(dev_prepared, dev_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pipelines and ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "# subsets data to make next steps faster\n",
    "train_subset = train_pd.sample(n = 1000, random_state = 0)\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "# TODO replace with sklearn's stratified splitter???\n",
    "shuffled = train_subset.sample(frac=1)\n",
    "split = round(train_subset.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# TODO is this the best way to separate out the labels from the features???\n",
    "train_labels = train_data[\"Category\"]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "# see Chap 2 transformation pipelines\n",
    "\n",
    "class DataFrameSelector( BaseEstimator, TransformerMixin): \n",
    "    def __init__( self, attribute_names): \n",
    "        self.attribute_names = attribute_names \n",
    "        \n",
    "    def fit( self, X, y = None): \n",
    "        return self \n",
    "    \n",
    "    def transform( self, X): \n",
    "        return X[ self.attribute_names].values\n",
    "\n",
    "    \n",
    "num_features = [\"X\", \"Y\"]\n",
    "cat_features = [\"DayOfWeek\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(num_features))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(cat_features)),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list = [\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "train_prepared = full_pipeline.fit_transform(train_data)\n",
    "print(train_prepared[0])\n",
    "print(train_prepared[400])\n",
    "print(train_prepared.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "dev_prepared = full_pipeline.fit_transform(dev_data)\n",
    "print(dev_prepared[0])\n",
    "print(dev_prepared[50])\n",
    "print(dev_prepared.shape)\n",
    "print(dev_labels.shape)\n",
    "\n",
    "# see Chap 7\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "voting_clf = VotingClassifier( estimators =[(\"lr\", log_clf), (\"knn\", knn_clf)], voting = \"hard\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, voting_clf):\n",
    "    clf.fit(train_prepared, train_labels)\n",
    "    y_pred = clf.predict(dev_prepared)\n",
    "    print(clf.__class__.__name__, accuracy_score( dev_labels, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
