{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "test notebook to figure out how sklearn pipeslines work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads data\n",
    "train_pd = pd.read_csv(\"../data/raw/train.csv.zip\", compression=\"zip\")\n",
    "test_pd = pd.read_csv(\"../data/raw/test.csv.zip\", compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the usual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangyq\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\yangyq\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\yangyq\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19817321435689514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "shuffled = train_pd.sample(frac=1)\n",
    "split = round(train_pd.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# splits the labels from the features\n",
    "features = [\"X\", \"Y\"]\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data[\"Category\"]\n",
    "\n",
    "dev_features = dev_data[features]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "test_features = test_pd[features]\n",
    "\n",
    "# does a silly transformation\n",
    "def silly(df):\n",
    "    return df.X + df.Y\n",
    "\n",
    "train_features[\"Z\"] = silly(train_features)\n",
    "dev_features[\"Z\"] = silly(dev_features)\n",
    "test_features[\"Z\"] = silly(test_features)\n",
    "\n",
    "# uses a simple knn\n",
    "clsfr = KNeighborsClassifier(n_neighbors = 3)\n",
    "clsfr.fit(train_features, train_labels)\n",
    "\n",
    "# checks basic accuracy\n",
    "score = clsfr.score(dev_features, dev_labels)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangyq\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\yangyq\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20146461741710278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "shuffled = train_pd.sample(frac=1)\n",
    "split = round(train_pd.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# splits the labels from the features\n",
    "features = [\"X\", \"Y\"]\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data[\"Category\"]\n",
    "\n",
    "dev_features = dev_data[features]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "test_features = test_pd[features]\n",
    "\n",
    "# see https://stackoverflow.com/questions/33091376/python-what-is-exactly-sklearn-pipeline-pipeline\n",
    "\n",
    "class MyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass # nothing to init\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self # no fitting\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        def silly(df):\n",
    "            return df.X + df.Y\n",
    "        X[\"Z\"] = silly(X)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "# use pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('silly', MyTransformer()),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors = 3)),\n",
    "])\n",
    "_ = pipeline.fit(train_features, train_labels)\n",
    "# Now evaluate all steps on test set\n",
    "score = pipeline.score(dev_features, dev_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pipelines on both numeric and categorical features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-122.42050707   37.75854554    0.            0.            0.\n",
      "    0.            0.            0.            1.        ]\n",
      "[-122.42701963   37.78019212    0.            1.            0.\n",
      "    0.            0.            0.            0.        ]\n",
      "(800, 9)\n",
      "(800,)\n",
      "[-122.42008098   37.76508154    1.            0.            0.\n",
      "    0.            0.            0.            0.        ]\n",
      "[-122.41251534   37.78047775    0.            0.            0.\n",
      "    0.            1.            0.            0.        ]\n",
      "(199, 9)\n",
      "(199,)\n",
      "0.1306532663316583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# subsets data to make next steps faster\n",
    "train_subset = train_pd.sample(n = 1000, random_state = 0)\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "# TODO replace with sklearn's stratified splitter???\n",
    "shuffled = train_subset.sample(frac=1)\n",
    "split = round(train_subset.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# TODO is this the best way to separate out the labels from the features???\n",
    "train_labels = train_data[\"Category\"]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "# see Chap 2 transformation pipelines\n",
    "\n",
    "class DataFrameSelector( BaseEstimator, TransformerMixin): \n",
    "    def __init__( self, attribute_names): \n",
    "        self.attribute_names = attribute_names \n",
    "        \n",
    "    def fit( self, X, y = None): \n",
    "        return self \n",
    "    \n",
    "    def transform( self, X): \n",
    "        return X[ self.attribute_names].values\n",
    "\n",
    "    \n",
    "num_features = [\"X\", \"Y\"]\n",
    "cat_features = [\"DayOfWeek\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(num_features))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(cat_features)),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list = [\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "train_prepared = full_pipeline.fit_transform(train_data)\n",
    "print(train_prepared[0])\n",
    "print(train_prepared[400])\n",
    "print(train_prepared.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "dev_prepared = full_pipeline.fit_transform(dev_data)\n",
    "print(dev_prepared[0])\n",
    "print(dev_prepared[50])\n",
    "print(dev_prepared.shape)\n",
    "print(dev_labels.shape)\n",
    "\n",
    "# TODO how to get the list of learned encodings???\n",
    "# print(cat_pipeline)\n",
    "# print(full_pipeline)\n",
    "\n",
    "\n",
    "# reuse pipeline code from previous section to classify\n",
    "clf_pipeline = Pipeline([\n",
    "    ('clf', KNeighborsClassifier(n_neighbors = 3))\n",
    "])\n",
    "\n",
    "_ = clf_pipeline.fit(train_prepared, train_labels)\n",
    "# Now evaluate all steps on test set\n",
    "score = clf_pipeline.score(dev_prepared, dev_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pipelines and gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-122.40648197   37.78273179    0.            0.            0.\n",
      "    1.            0.            0.            0.        ]\n",
      "[-122.4225269    37.79969436    0.            0.            1.\n",
      "    0.            0.            0.            0.        ]\n",
      "(800, 9)\n",
      "(800,)\n",
      "[-122.40296132   37.7121195     0.            0.            0.\n",
      "    1.            0.            0.            0.        ]\n",
      "[-122.44732906   37.79893789    0.            0.            0.\n",
      "    0.            1.            0.            0.        ]\n",
      "(199, 9)\n",
      "(199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangyq\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.202):\n",
      "{'knn__n_neighbors': 59}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# subsets data to make next steps faster\n",
    "train_subset = train_pd.sample(n = 1000, random_state = 0)\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "# TODO replace with sklearn's stratified splitter???\n",
    "shuffled = train_subset.sample(frac=1)\n",
    "split = round(train_subset.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# TODO is this the best way to separate out the labels from the features???\n",
    "train_labels = train_data[\"Category\"]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "# see Chap 2 transformation pipelines\n",
    "\n",
    "class DataFrameSelector( BaseEstimator, TransformerMixin): \n",
    "    def __init__( self, attribute_names): \n",
    "        self.attribute_names = attribute_names \n",
    "        \n",
    "    def fit( self, X, y = None): \n",
    "        return self \n",
    "    \n",
    "    def transform( self, X): \n",
    "        return X[ self.attribute_names].values\n",
    "\n",
    "    \n",
    "num_features = [\"X\", \"Y\"]\n",
    "cat_features = [\"DayOfWeek\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(num_features))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(cat_features)),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list = [\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "train_prepared = full_pipeline.fit_transform(train_data)\n",
    "print(train_prepared[0])\n",
    "print(train_prepared[400])\n",
    "print(train_prepared.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "dev_prepared = full_pipeline.fit_transform(dev_data)\n",
    "print(dev_prepared[0])\n",
    "print(dev_prepared[50])\n",
    "print(dev_prepared.shape)\n",
    "print(dev_labels.shape)\n",
    "\n",
    "# TODO how to get the list of learned encodings???\n",
    "# print(cat_pipeline)\n",
    "# print(full_pipeline)\n",
    "\n",
    "\n",
    "# reuse pipeline code from previous section to classify\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf_pipeline = Pipeline(steps = [\n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "# see https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 9, 17, 23]\n",
    "}\n",
    "search = GridSearchCV(clf_pipeline, param_grid, iid = False, cv = 5, return_train_score = False)\n",
    "\n",
    "_ = search.fit(train_prepared, train_labels)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "# # Now evaluate all steps on test set\n",
    "# score = search.score(dev_prepared, dev_labels)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with pipelines and ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-122.40340479   37.77542071    0.            0.            1.\n",
      "    0.            0.            0.            0.        ]\n",
      "[-122.41205414   37.78161364    0.            0.            0.\n",
      "    0.            1.            0.            0.        ]\n",
      "(800, 9)\n",
      "(800,)\n",
      "[-122.37493094   37.72966226    0.            0.            0.\n",
      "    1.            0.            0.            0.        ]\n",
      "[-122.40156097   37.78408887    0.            0.            0.\n",
      "    0.            1.            0.            0.        ]\n",
      "(199, 9)\n",
      "(199,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangyq\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\yangyq\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-4f1df96b6a44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_prepared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_prepared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "# subsets data to make next steps faster\n",
    "train_subset = train_pd.sample(n = 1000, random_state = 0)\n",
    "\n",
    "# shuffles, then splits into train and dev sets\n",
    "# TODO replace with sklearn's stratified splitter???\n",
    "shuffled = train_subset.sample(frac=1)\n",
    "split = round(train_subset.shape[0] * 0.8)\n",
    "train_data = shuffled[:split]\n",
    "dev_data = shuffled[split+1:]\n",
    "\n",
    "# TODO is this the best way to separate out the labels from the features???\n",
    "train_labels = train_data[\"Category\"]\n",
    "dev_labels = dev_data[\"Category\"]\n",
    "\n",
    "# see Chap 2 transformation pipelines\n",
    "\n",
    "class DataFrameSelector( BaseEstimator, TransformerMixin): \n",
    "    def __init__( self, attribute_names): \n",
    "        self.attribute_names = attribute_names \n",
    "        \n",
    "    def fit( self, X, y = None): \n",
    "        return self \n",
    "    \n",
    "    def transform( self, X): \n",
    "        return X[ self.attribute_names].values\n",
    "\n",
    "    \n",
    "num_features = [\"X\", \"Y\"]\n",
    "cat_features = [\"DayOfWeek\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(num_features))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(cat_features)),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list = [\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline)\n",
    "])\n",
    "\n",
    "train_prepared = full_pipeline.fit_transform(train_data)\n",
    "print(train_prepared[0])\n",
    "print(train_prepared[400])\n",
    "print(train_prepared.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\n",
    "dev_prepared = full_pipeline.fit_transform(dev_data)\n",
    "print(dev_prepared[0])\n",
    "print(dev_prepared[50])\n",
    "print(dev_prepared.shape)\n",
    "print(dev_labels.shape)\n",
    "\n",
    "# see Chap 7\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "voting_clf = VotingClassifier( estimators =[(\"lr\", log_clf), (\"knn\", knn_clf)], voting =' hard')\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, voting_clf):\n",
    "    clf.fit(train_prepared, train_labels)\n",
    "    y_pred = clf.predict(dev_prepared)\n",
    "    print(clf.__class__.__name__, accuracy_score( y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
